<h1>README for visualizationCodeForSOMA</h1>
<p>This repository provides the code used to visualize results of training a surrogate neural network on data obtained by running the SOMA simulation, an idealized version of MPAS-Ocean.</p>
<p>Here is an outline of the files provided here and what they entail. The user should note that training results and masking files have not at this time been provided, so a user would have to implement there own, most likely altering the first several lines of each Python script.</p>

<ol>
  <li><b>anova.py</b> - anova.py provides the code to compute the ANOVA statistic as taken between all available test cases. The logic here is to compute ANOVA where each input array is a different normalized output array for a specific test case, showcasing the relationship between the input parameter and the output value. If there is a p-value that is less than 0.05, we generally reject the null hypothesis that there is no relationship between the input and the output. The strength of the f value then represents the strenght of the relationship between input and output.</li>
  <li><b>gettingGMValues.py</b> - Although this could be changed to gettingRediValues.py, gettingCVMixValues.py, etc., the premise is to obtain the input value for this specific input perturbation for all provided test cases.</li>
  <li><b>graphingActualPredictedError.py</b> - This code results in a 4 by 3 grid of heatmaps representing the AMOC. The first column represents the actual values as provided, the second column represents the prediction from our training, and the third represents the squared error between the two. Each row is a different variable, and the user can select which range of variables they want to analyze. The predicted and actual are plotted on the same scale for ease of comparison.</li>
  <li><b>graphingGMvsError.py</b> - This is a simple scatter plot between the GM and the mean squared error across all variables for that value of GM. The aim of this graph is to understand if there is some relationship between GM value (or other input parameter) and the error in the results. Thus far, no strong correlation has been detected.</li>
  <li><b>graphingMSE.py</b> - This Python script plots a bar chart where each bar represents the mean squared error for a single variable as computed between actual and predicted for testing. The total mean squared error is displayed as a horizontal axis across the bar plot.</li>
  <li><b>graphingNC.py</b> - This Python script plots a bar chart where each bar represents the NC error for a single variable as computed between actual and predicted for testing. Unlike MSE, the NC can be negative.</li>
  <li><b>graphingVariablewiseGMvsError.py</b> - This graphs a heatmap where the y axis are the different values of GM (or another input parameter), normalized and in order. The x axis is then each of the variables, and the heatmap colors at each position represent the mean squared error between actual and predicted for that variable at that GM/other input variable. It provides greater context to the graphingGMvsError.py script.</li>
</ol>
